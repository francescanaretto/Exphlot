{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b73d580a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (201901520.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Input \u001B[1;32mIn [1]\u001B[1;36m\u001B[0m\n\u001B[1;33m    from rocket_functions import generate_kernels, apply_kernels, apply_kernels_jagged, run_additional(training_data, test_data, num_runs = 10, num_kernels = 10_000)\u001B[0m\n\u001B[1;37m                                                                                                      ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from rocket_functions import generate_kernels, apply_kernels, apply_kernels_jagged, run_additional(training_data, test_data, num_runs = 10, num_kernels = 10_000)\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "import imblearn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08e23c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(X_training, X_test):   \n",
    "    dataref = np.concatenate((X_training, X_test), axis = 0)\n",
    "    dataref_plain = dataref.reshape(dataref.shape[0]*dataref.shape[1], 1)\n",
    "    X_training_plain = X_training.reshape(X_training.shape[0]*X_training.shape[1], 1)\n",
    "    X_test_plain = X_test.reshape(X_test.shape[0]*X_test.shape[1], 1)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(dataref_plain)\n",
    "    X_training_norm = scaler.transform(X_training_plain)\n",
    "    X_test_norm = scaler.transform(X_test_plain)\n",
    "    X_training_norm = X_training_norm.reshape(X_training.shape[0], X_training.shape[1])\n",
    "    X_test_norm = X_test_norm.reshape(X_test.shape[0], X_test.shape[1])\n",
    "    return X_training_norm, X_test_norm\n",
    "\n",
    "def dataset_name_f(strrischio, overunder, normst):\n",
    "    str_overunder_dataset = ''\n",
    "    str_norm_dataset = ''\n",
    "    if normst != '':\n",
    "        str_norm_dataset = '_' + normst\n",
    "    if overunder != '':\n",
    "        if strrischio == '2' or strrischio == '5':\n",
    "            str_overunder_dataset = '_' + overunder +'_40_60'  \n",
    "        else:\n",
    "            str_overunder_dataset = '_' + overunder +'_50_50'\n",
    "    dataset_name = 'rischio' + strrischio + str_norm_dataset + str_overunder_dataset\n",
    "    return dataset_name\n",
    "\n",
    "\n",
    "def dataset_name_pad(strrischio, overunder, normst, tipo = 'train'):\n",
    "    str_overunder_dataset = ''\n",
    "    str_norm_dataset = ''\n",
    "    if normst != '':\n",
    "        str_norm_dataset = '_' + normst\n",
    "    if overunder != '':\n",
    "        if strrischio == '2' or strrischio == '5':\n",
    "            str_overunder_dataset = '_' + overunder +'_40_60'  \n",
    "        else:\n",
    "            str_overunder_dataset = '_' + overunder +'_50_50'\n",
    "    if tipo == 'train':\n",
    "        dataset_name = 'training' + strrischio + str_norm_dataset + str_overunder_dataset + '_splitpad'\n",
    "    elif tipo == 'test':\n",
    "        dataset_name = 'test' + strrischio + str_norm_dataset + '_splitpad'     \n",
    "    else:\n",
    "        print('specifica tipo')\n",
    "    return dataset_name\n",
    "\n",
    "\n",
    "def read_dataset_padsplit(dataset_folder, rischio, scaling, overunder, perc_min = 40, perc_magg = 60):\n",
    "    if overunder != '' and scaling != '':\n",
    "        add_str_ytrain = add_str_xtrain  = '_' + scaling +'_' + overunder + '_' + str(perc_min) + '_' + str(perc_magg)\n",
    "    elif overunder != '' and scaling == '' :\n",
    "        add_str_ytrain  = '_' + overunder + '_' + str(perc_min) + '_' + str(perc_magg)\n",
    "    elif overunder == '':\n",
    "        add_str_ytrain = ''\n",
    "    else:\n",
    "        print('PROBLEMA', overunder, scaling )\n",
    "        return\n",
    "    with open(dataset_folder + '/pad_split/rischio' + rischio + '/' + dataset_name_pad(rischio, overunder, scaling, tipo = 'train') + '.p', 'rb') as f:\n",
    "        x_train = pickle.load(f)\n",
    "        X_training = x_train.astype(np.float64)\n",
    "    with open(dataset_folder + '/pad_incima/rischio' + rischio + '/label_training' + rischio + add_str_ytrain + '.p', 'rb') as f:\n",
    "        y_train = pickle.load(f)\n",
    "        Y_training = y_train.astype(np.int32)\n",
    "    with open(dataset_folder + '/pad_split/rischio' + rischio + '/' + dataset_name_pad(rischio, overunder, scaling, tipo = 'test') + '.p', 'rb') as f:\n",
    "        x_test = pickle.load(f)\n",
    "        X_test = x_test.astype(np.float64)\n",
    "    with open(dataset_folder + '/pad_incima/rischio' + rischio + '/label_test' + rischio + '.p', 'rb') as f:\n",
    "        y_test = pickle.load(f)\n",
    "        Y_test = y_test.astype(np.int32)\n",
    "    return X_training, Y_training, X_test, Y_test\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60312aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_kernels_perc(rischio):\n",
    "    if rischio == '2' or rischio == '3':\n",
    "        f = open('/Users/Administrator/Desktop/tesi/rocket-prove/kernels_2_3.pckl', 'rb')\n",
    "        kernels = pickle.load(f)\n",
    "        f.close()\n",
    "        perc_min = 40\n",
    "        perc_mag = 60    \n",
    "    else:\n",
    "        f = open('/Users/Administrator/Desktop/tesi/rocket-prove/kernels5.pckl', 'rb')\n",
    "        kernels = pickle.load(f)\n",
    "        f.close()\n",
    "        perc_min = perc_mag = 50\n",
    "    return kernels, perc_min, perc_mag\n",
    "\n",
    "def run_kernels(X_training, X_test, kernels):\n",
    "    inizio = time.time()\n",
    "    X_training_transform = apply_kernels(X_training, kernels)\n",
    "    fine = time.time()\n",
    "    print('Running kernels su train:' , fine - inizio)\n",
    "    inizio = time.time()\n",
    "    X_test_transform = apply_kernels(X_test, kernels)\n",
    "    fine = time.time()\n",
    "    print('Running kernels su test:' , fine - inizio)\n",
    "    X_training_transform, X_test_transform = normalization(X_training_transform, X_test_transform)\n",
    "    max_iter = np.ceil(10**7 / len(X_training_transform))\n",
    "    return(X_training_transform, X_test_transform, max_iter)\n",
    "\n",
    "def overunder_str(overunder, perc_min, perc_magg):\n",
    "    if overunder != '':\n",
    "        overunder_p = overunder + '_' + str(perc_min) + '_' + str(perc_magg)\n",
    "    else:\n",
    "        overunder_p = 'no over-under'\n",
    "    return(overunder_p)\n",
    "\n",
    "\n",
    "def read_dataset_modified(dataset_folder, rischio, scaling, overunder, perc_min = 40, perc_magg = 60):\n",
    "    if overunder != '' and scaling != '':\n",
    "        add_str_ytrain = add_str_xtrain  = '_' + scaling +'_' + overunder + '_' + str(perc_min) + '_' + str(perc_magg)\n",
    "        add_str_xtest  = '_' + scaling\n",
    "        add_str_ytest = ''\n",
    "    elif overunder != '' and scaling == '' :\n",
    "        add_str_ytrain = add_str_xtrain = '_' + overunder + '_' + str(perc_min) + '_' + str(perc_magg)\n",
    "        add_str_ytest = add_str_xtest = ''\n",
    "    elif overunder == '' and scaling != '' :\n",
    "        add_str_ytrain = add_str_ytest = ''\n",
    "        add_str_xtrain = add_str_xtest = '_' + scaling\n",
    "    elif overunder == '' and scaling == '' :\n",
    "        add_str_ytrain = add_str_ytest = add_str_xtrain = add_str_xtest = ''\n",
    "    else:\n",
    "        print('PROBLEMA', overunder, scaling )\n",
    "        return\n",
    "    with open(dataset_folder + '/training' + rischio + add_str_xtrain + '.p', 'rb') as f:\n",
    "        x_train = pickle.load(f)\n",
    "        X_training = x_train.astype(np.float64)\n",
    "    with open(dataset_folder + '/label_training' + rischio + add_str_ytrain + '.p', 'rb') as f:\n",
    "        y_train = pickle.load(f)\n",
    "        Y_training = y_train.astype(np.int32)\n",
    "    with open(dataset_folder + '/test' + rischio + add_str_xtest + '.p', 'rb') as f:\n",
    "        x_test = pickle.load(f)\n",
    "        X_test = x_test.astype(np.float64)\n",
    "    with open(dataset_folder + '/label_test' + rischio + add_str_ytest + '.p', 'rb') as f:\n",
    "        y_test = pickle.load(f)\n",
    "        Y_test = y_test.astype(np.int32)\n",
    "    return X_training, Y_training, X_test, Y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a0457a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SGD classifier with balanced accuracy\n",
    "def results_SGD_balanced(rischio, perc_min, perc_magg, kernels, overunder_list, scaling_list, results_file):\n",
    "    dataset_folder = '/Users/Administrator/Desktop/tesi/datasets_tesi/'\n",
    "    for scaling in scaling_list:\n",
    "        for overunder in overunder_list:\n",
    "            #X_training, Y_training, X_test, Y_test = read_dataset_modified(dataset_folder, rischio, scaling,\n",
    "            #                                                        overunder, perc_min, perc_magg)\n",
    "            X_training, Y_training, X_test, Y_test = read_dataset_padsplit(dataset_folder, rischio, scaling, \n",
    "                                                                          overunder, perc_min, perc_magg)\n",
    "            X_training_transform, X_test_transform, max_iter = run_kernels(X_training, X_test, kernels)\n",
    "            param_grid = {'alpha' : list(np.logspace(-3, 3, 10)), 'class_weight' : [None, 'balanced']}\n",
    "            classifier = GridSearchCV(SGDClassifier(loss = 'log', max_iter = max_iter, early_stopping  = True,\n",
    "                                n_iter_no_change = 12, random_state = 42), param_grid, scoring = 'balanced_accuracy')\n",
    "            classifier.fit(X_training_transform, Y_training)\n",
    "            train_predictions = classifier.predict(X_training_transform)\n",
    "            \n",
    "            overunder_p = overunder_str(overunder, perc_min, perc_magg)\n",
    "            \n",
    "            with open(results_file, 'a') as f:\n",
    "                f.write('TRAINING' + rischio + ' ' + scaling + ' ' + overunder_p + ' ' +\n",
    "                        str(classifier.best_params_) + ' ' + str(classifier.scorer_)  + '\\n' + str(classification_report(Y_training, train_predictions)) + '\\n')\n",
    "                predictions = classifier.predict(X_test_transform)\n",
    "                f.write('TEST' + rischio + ' ' + scaling + ' ' + overunder_p + ' ' +\n",
    "                        str(classifier.best_params_) + ' ' + str(classifier.scorer_) + '\\n' + str(classification_report(Y_test, predictions)) + '\\n')\n",
    "    return classifier\n",
    "\n",
    "def results_SGD(rischio, perc_min, perc_magg, kernels, overunder_list, scaling_list, results_file):\n",
    "    dataset_folder = '/Users/Administrator/Desktop/tesi/datasets_tesi/'\n",
    "    for scaling in scaling_list:\n",
    "        for overunder in overunder_list:\n",
    "            #X_training, Y_training, X_test, Y_test = read_dataset_modified(dataset_folder, rischio, scaling,\n",
    "            #                                                        overunder, perc_min, perc_magg)\n",
    "            \n",
    "            X_training, Y_training, X_test, Y_test = read_dataset_padsplit(dataset_folder, rischio, scaling, \n",
    "                                                               overunder, perc_min, perc_magg)\n",
    "            X_training_transform, X_test_transform, max_iter = run_kernels(X_training, X_test, kernels)\n",
    "            \n",
    "            param_grid = {'alpha' : list(np.logspace(-3, 3, 10)), 'class_weight' : [None, 'balanced']}\n",
    "            classifier = GridSearchCV(SGDClassifier(loss = 'log', max_iter = max_iter, \n",
    "                    early_stopping  = True, n_iter_no_change = 12, random_state = 42), param_grid)\n",
    "            inizio = time.time()\n",
    "            classifier.fit(X_training_transform, Y_training)\n",
    "            fine = time.time()\n",
    "            print('training time: ', fine - inizio)\n",
    "            inizio = time.time()\n",
    "            train_predictions = classifier.predict(X_training_transform)\n",
    "            fine = time.time()\n",
    "            print('prediction time su training: ', fine - inizio)\n",
    "            overunder_p = overunder_str(overunder, perc_min, perc_magg)\n",
    "            with open(results_file, 'a') as f:\n",
    "                f.write('TRAINING' + rischio + ' ' + scaling + ' ' + overunder_p + ' ' +\n",
    "                        str(classifier.best_params_) + '\\n' + str(classification_report(Y_training, train_predictions)) + '\\n')\n",
    "                inizio = time.time()\n",
    "                predictions = classifier.predict(X_test_transform)\n",
    "                fine = time.time()\n",
    "                print('prediction time su test: ', fine - inizio)\n",
    "                f.write('TEST' + rischio + ' ' + scaling + ' ' + overunder_p + ' ' +\n",
    "                        str(classifier.best_params_) + '\\n' + str(classification_report(Y_test, predictions)) + '\\n')\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac542ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_RidgeCV(rischio, perc_min, perc_magg, kernels, overunder_list, scaling_list, results_file):\n",
    "    #dataset_folder = '/Users/Administrator/Desktop/tesi/datasets_tesi/rischio' + rischio\n",
    "    dataset_folder = '/Users/Administrator/Desktop/tesi/datasets_tesi/'\n",
    "    for scaling in scaling_list:\n",
    "        for overunder in overunder_list:\n",
    "            #X_training, Y_training, X_test, Y_test = read_dataset_modified(dataset_folder, rischio, scaling,\n",
    "            #                                                        overunder, perc_min, perc_magg)\n",
    "            X_training, Y_training, X_test, Y_test = read_dataset_padsplit(dataset_folder, rischio, scaling, \n",
    "                                                               overunder, perc_min, perc_magg)\n",
    "            \n",
    "            X_training_transform, X_test_transform, max_iter = run_kernels(X_training, X_test, kernels)\n",
    "            \n",
    "            if perc_min != 50:    \n",
    "                class_weight_list=[None, 'balanced'] \n",
    "                scoring_list = [None, 'balanced_accuracy']\n",
    "            else:\n",
    "                class_weight_list = [None]\n",
    "                scoring_list = [None]\n",
    "            \n",
    "            for scoring in scoring_list:\n",
    "                for class_weight in class_weight_list:\n",
    "                    classifier = RidgeClassifierCV(alphas = np.logspace(-3, 3, 10), normalize = False,\n",
    "                                                   scoring = scoring, class_weight = class_weight)\n",
    "                    classifier.fit(X_training_transform, Y_training)\n",
    "                    train_predictions = classifier.predict(X_training_transform)\n",
    "                    overunder_p = overunder_str(overunder, perc_min, perc_magg)\n",
    "                    with open(results_file, 'a') as f:\n",
    "                        f.write('TRAINING' + rischio + ' ' + scaling + ' ' + overunder_p + ' alpha:' +\n",
    "                                str(classifier.alpha_) + ' ' + 'class_weight: ' + str(class_weight) + \n",
    "                                ' scoring:' + str(scoring) + '\\n' + str(classification_report(Y_training, train_predictions)) + '\\n')\n",
    "                        predictions = classifier.predict(X_test_transform)\n",
    "                        f.write('TEST' + rischio + ' ' + scaling + ' ' + overunder_p + ' alpha:' +\n",
    "                                str(classifier.alpha_) + ' ' + 'class_weight: ' + str(class_weight) + \n",
    "                                ' scoring:' + str(scoring) + '\\n' + str(classification_report(Y_test, predictions)) + '\\n')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c41d54c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "900101e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rischio = '5'\n",
    "scaling = 'std' \n",
    "overunder = 'randover'\n",
    "perc_min = '40'\n",
    "perc_mag = '60'\n",
    "dataset_folder = '/Users/Administrator/Desktop/tesi/datasets_tesi/pad_incima/rischio' + rischio\n",
    "X_training, Y_training, X_test, Y_test = read_dataset_modified(dataset_folder, rischio, scaling,                                                            overunder, perc_min = '40', perc_magg = '60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a81b832a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time 26.907869815826416\n",
      "prediction training time 0.18318486213684082\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RidgeClassifierCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_15204/3295427819.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[0moverunder_p\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moverunder_str\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moverunder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mperc_min\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mperc_mag\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m print('TRAINING' + rischio + ' ' + scaling + ' ' + overunder_p + ' ' +\n\u001B[1;32m---> 16\u001B[1;33m             str(classifier.best_params_) + '\\n' + str(classification_report(Y_training, train_predictions)) + '\\n')\n\u001B[0m\u001B[0;32m     17\u001B[0m \u001B[0ma\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[0mpredictions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mclassifier\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_test_transform\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'RidgeClassifierCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "#RIDGECV SINGOLO\n",
    "X_training_transform, X_test_transform, max_iter = run_kernels(X_training, X_test, kernels)\n",
    "class_weight = None\n",
    "scoring = None\n",
    "classifier = RidgeClassifierCV(alphas = np.logspace(-3, 3, 10), normalize = False,\n",
    "                               scoring = scoring, class_weight = class_weight)\n",
    "a = time.time()\n",
    "classifier.fit(X_training_transform, Y_training)\n",
    "b = time.time()\n",
    "print('training time', b - a)\n",
    "a = time.time()\n",
    "train_predictions = classifier.predict(X_training_transform)\n",
    "b = time.time()\n",
    "print('prediction training time', b - a)\n",
    "overunder_p = overunder_str(overunder, perc_min, perc_mag)\n",
    "print('TRAINING' + rischio + ' ' + scaling + ' ' + overunder_p + ' alpha:' +\n",
    "        str(classifier.alpha_) + ' ' + 'class_weight: ' + str(class_weight) + \n",
    "        ' scoring:' + str(scoring) + '\\n' + str(classification_report(Y_training, train_predictions)) + '\\n')\n",
    "a = time.time()\n",
    "predictions = classifier.predict(X_test_transform)\n",
    "b = time.time()\n",
    "print('prediction test time', b - a)\n",
    "print('TEST' + rischio + ' ' + scaling + ' ' + overunder_p + ' alpha:' +\n",
    "    str(classifier.alpha_) + ' ' + 'class_weight: ' + str(class_weight) + \n",
    "    ' scoring:' + str(scoring) + '\\n' + str(classification_report(Y_test, predictions)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c065a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/Administrator/Desktop/tesi/rocket-prove/MODELLI_SCELTI/voronoi/' + 'SDG_' + dataset_name_f(rischio, overunder, scaling) + '_modello.sav'\n",
    "pickle.dump(classifier, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5cd4a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running kernels su train: 65.61821293830872\n",
      "Running kernels su test: 16.896856784820557\n",
      "training time classifier:  428.3139498233795\n",
      "prediction time classifier su training:  0.14063453674316406\n",
      "TRAINING5 std randover_40_60 {'alpha': 0.1, 'class_weight': None}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89      2140\n",
      "           1       0.92      0.93      0.93      3210\n",
      "\n",
      "    accuracy                           0.91      5350\n",
      "   macro avg       0.91      0.91      0.91      5350\n",
      "weighted avg       0.91      0.91      0.91      5350\n",
      "\n",
      "\n",
      "prediction time classifier su test:  0.03125333786010742\n",
      "TEST5 std randover_40_60 {'alpha': 0.1, 'class_weight': None}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88       477\n",
      "           1       0.93      0.92      0.93       803\n",
      "\n",
      "    accuracy                           0.91      1280\n",
      "   macro avg       0.90      0.90      0.90      1280\n",
      "weighted avg       0.91      0.91      0.91      1280\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_training_transform, X_test_transform, max_iter = run_kernels(X_training, X_test, kernels)\n",
    "param_grid = {'alpha' : list(np.logspace(-3, 3, 10)), 'class_weight' : [None, 'balanced']}\n",
    "classifier = GridSearchCV(SGDClassifier(loss = 'log', max_iter = max_iter, \n",
    "        early_stopping  = True, n_iter_no_change = 12, random_state = 42), param_grid)\n",
    "inizio = time.time()\n",
    "classifier.fit(X_training_transform, Y_training)\n",
    "fine = time.time()\n",
    "print('training time classifier: ', fine - inizio)\n",
    "inizio = time.time()\n",
    "train_predictions = classifier.predict(X_training_transform)\n",
    "fine = time.time()\n",
    "print('prediction time classifier su training: ', fine - inizio)\n",
    "overunder_p = overunder_str(overunder, perc_min, perc_mag)\n",
    "\n",
    "print('TRAINING' + rischio + ' ' + scaling + ' ' + overunder_p + ' ' +\n",
    "        str(classifier.best_params_) + '\\n' + str(classification_report(Y_training, train_predictions)) + '\\n')\n",
    "inizio = time.time()\n",
    "predictions = classifier.predict(X_test_transform)\n",
    "fine = time.time()\n",
    "print('prediction time classifier su test: ', fine - inizio)\n",
    "print('TEST' + rischio + ' ' + scaling + ' ' + overunder_p + ' ' +\n",
    "        str(classifier.best_params_) + '\\n' + str(classification_report(Y_test, predictions)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c01d09a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/Administrator/Desktop/tesi/rocket-prove/kernels_4.pckl'\n",
    "filehandler = open(file,\"wb\")\n",
    "pickle.dump(kernels,filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4dd6df81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Administrator/Desktop/tesi/datasets_tesi/\n"
     ]
    }
   ],
   "source": [
    "#CALCOLI NUOVI SUI DATASET PADDATI\n",
    "scaling_list = ['std'] \n",
    "overunder_list = ['randover']\n",
    "dataset_folder = '/Users/Administrator/Desktop/tesi/datasets_tesi/'\n",
    "results_file = '/Users/Administrator/Desktop/tesi/rocket-prove/rocket_trials_results/pad_split/SGD_rischio' + rischio + '.txt'\n",
    "classifier = results_SGD(rischio, perc_min, perc_mag, kernels, overunder_list, scaling_list, results_file)\n",
    "filename = '/Users/Administrator/Desktop/tesi/rocket-prove/modelli_salvati/pad_split/' + 'SGD_' + dataset_name_f(rischio, overunder, scaling) + '_modello.sav'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1b1143f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Administrator/Desktop/tesi/datasets_tesi/\n"
     ]
    }
   ],
   "source": [
    "classifier = results_SGD_balanced(rischio, perc_min, perc_mag, kernels, overunder_list, scaling_list, results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "029c448d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Administrator/Desktop/tesi/datasets_tesi/\n"
     ]
    }
   ],
   "source": [
    "results_file = '/Users/Administrator/Desktop/tesi/rocket-prove/rocket_trials_results/pad_split/ridgeCV_rischio' + rischio + '.txt'\n",
    "results_RidgeCV(rischio, perc_min, perc_mag, kernels, overunder_list, scaling_list, results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f90a16a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rischio_list = ['2'] \n",
    "for rischio in rischio_list:\n",
    "    kernels, perc_min, perc_mag = choose_kernels_perc(rischio)\n",
    "    output = '/Users/Administrator/Desktop/tesi/rocket-prove/rocket_trials_results/SDG_rischio' + rischio + '.txt'\n",
    "    results_SGD(rischio, perc_min, perc_mag, kernels, output)\n",
    "    if perc_min!=50:\n",
    "        results_SGD_balanced(rischio, perc_min, perc_mag, kernels, output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad106dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('kernels.pckl', 'rb')\n",
    "kernels = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('kernels2.pckl', 'rb')\n",
    "kernels2 = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "rischio_list = ['2', '3', '4' , '5'] \n",
    "for rischio in rischio_list:\n",
    "    if rischio == '2' or rischio == '5':\n",
    "        perc_min = 40\n",
    "        perc_mag = 60\n",
    "        kernels = kernels\n",
    "    else:\n",
    "        perc_min = perc_mag = 50\n",
    "        kernels = kernels2\n",
    "    output = '/Users/Administrator/Desktop/tesi/rocket-prove/ridgeCV_rischio' + rischio + '.txt'\n",
    "    results_RidgeCV(rischio, perc_min, perc_mag, kernels, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ddf4012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"f = open('kernels.pckl', 'rb')\\nkernels = pickle.load(f)\\nf.close()\\n\\nf = open('kernels2.pckl', 'rb')\\nkernels2 = pickle.load(f)\\nf.close()\\n\\nrischio_list = ['2', '3', '4' , '5'] \\nfor rischio in rischio_list:\\n    if rischio == '2' or rischio == '5':\\n        perc_min = 40\\n        perc_mag = 60\\n        kernels = kernels\\n    else:\\n        perc_min = perc_mag = 50\\n        kernels = kernels2\\n    output = '/Users/Administrator/Desktop/tesi/rocket-prove/ridgeClassPG_rischio' + rischio + '.txt'\\n    results_RidgeClassPG(rischio, perc_min, perc_mag, kernels, output)\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('kernels.pckl', 'rb')\n",
    "kernels = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('kernels2.pckl', 'rb')\n",
    "kernels2 = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "rischio_list = ['2', '3', '4' , '5'] \n",
    "for rischio in rischio_list:\n",
    "    if rischio == '2' or rischio == '5':\n",
    "        perc_min = 40\n",
    "        perc_mag = 60\n",
    "        kernels = kernels\n",
    "    else:\n",
    "        perc_min = perc_mag = 50\n",
    "        kernels = kernels2\n",
    "    output = '/Users/Administrator/Desktop/tesi/rocket-prove/ridgeClassPG_rischio' + rischio + '.txt'\n",
    "    results_RidgeClassPG(rischio, perc_min, perc_mag, kernels, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb67b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('kernels_5k.pckl', 'rb')\n",
    "kernels = pickle.load(f)\n",
    "f.close()\n",
    "perc_min = 40\n",
    "perc_mag = 60\n",
    "rischio_list = ['2'] \n",
    "output = '/Users/Administrator/Desktop/tesi/rocket-prove/rocket_trials_results/SDG_5k_rischio' + rischio + '.txt'\n",
    "results_SGD(rischio, perc_min, perc_mag, kernels, output)\n",
    "if perc_min!=50:\n",
    "    results_SGD_balanced(rischio, perc_min, perc_mag, kernels, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa01b11e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}